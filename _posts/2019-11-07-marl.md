---
layout: post
title: Solving Routing Problems with Multi-Agent Reinforcement Learning
excerpt: "Routing problems can lend themselves well to the application of Reinforcement Learning (RL). They can be formatted as a sequential decision-making process, have relatively clear notions of when to apply penalties or rewards, and solutions can be evaluated quickly. One avenue of potential solutions that has not been explored much yet, is the application of Multi-Agent Reinforcement Learning (MARL)"
modified: 11/13/2019, 10:35:24
tags: [multi agent learning, reinforcement learning, deep reinformcement learning]
comments: false
category: mscproject
---

Routing problems are a common occurrence in many industry settings. Many organizations need, to different extents, move goods around between their locations, or between themselves and clients (think trucks, ships, airplanes, taxis, and so forth). This leads to an interest in finding optimal routing schedules for a wide variety of situations. Optimizing these schedules can lead to large cost reductions in different ways (operating costs, operating times, maintenance costs, environmental impact, to name a few). Especially in the case of large problems or problems with many constraints, small improvements can have big impacts. 

Traditionally, algorithms for solving these types of problems rely on one or more hand-crafted heuristics and perform an iterative search. That is to say, they start with one or more bad solutions, and try to improve those solutions over time by applying operations that are thought likely to decrease the solution's cost. A significant disadvantage of this approach is that it can take a long time to generate a solution of a desirable quality, running times which only increase as the problem size and complexity grows. This is problematic in cases where schedules need to be generated in short intervals (daily, for example), or in cases where a situation changes and a schedule has to be re-generated quickly. Beyond that, the solution quality of many of these algorithms drops significantly as the problem size and problem complexity grow. 

![Example of TSP and VPR solution](../../images/posts/marl-1.png)

Figure 1. Example of a TSP solution and a VRP solution.

The routing problems mentioned above generally fall into the category of combinatorial optimization algorithms. Problems in this category generally deal with finding some order on the input, assigning the elements of the input in some way, or picking a suitable subset of the input. They have a string history in not only Computer Science, but also in Applied Mathematics and Operations Research. Many of these problems are NP-complete and very difficult to solve at larger scales, unless some very specific assumptions and/or constraints are applied. A common example and basic routing problem is the Traveling Salesman Problem (TSP). Given a collection of points, the goal of the TSP is to found a shortest round-trip route. For an input with n points, the TSP has n! possible solutions, so the solution search space very quickly becomes immense. A wide variety of other routing problems exist that extent the TSP in some way, for example the Vehicle Routing Problem (VRP) is basically a TSP with multiple vehicles. 
Deep Learning my offer alternatives that address these shortcomings. If a model can be defined that can generate routing schedules, and that model can be trained to generate solutions of sufficient quality, it has the potential of being able to (re-)generate schedules much quicker than traditional algorithms. There is even some work linking the solving of TSPs to the neural structure of the human brain [1], which Neural Networks are based on. In recent years, there have been a couple of attempts to apply various Deep Learning techniques to Combinatorial Optimization problems [2][3][4]. They mainly focus on the TSP and VRP problems, with input of up to 100 points. Although the results are interesting, they leave something to be desired. Both the size and the complexity of the problems tackled in these works are very limited. Real-life situations are often not as neat as a simple TSP, nor are they so small. 
Routing problems can lend themselves well to the application of Reinforcement Learning (RL). They can be formatted as a sequential decision-making process, have relatively clear notions of when to apply penalties or rewards, and solutions can be evaluated quickly. One avenue of potential solutions that has not been explored much yet, is the application of Multi-Agent Reinforcement Learning (MARL) [2]. In this setting, a group of agents make decisions which collectively impact the RL environment. MARL approaches have the advantage of being easier to parallelize, and possibly being able to induce smaller model sizes. Additionally, there is the potential of agents learning from each other. In the case of routing problems, there is also often an intuitive separating of the problems into multiple agents. For example, each agent could represent a truck in a fleet of trucks.

![](../../images/posts/marl-2.png)

Figure 2 Structure of a single-agent Reinforcement Learning setup (top), and a Multi-Agent Reinforcement Learning setup (bottom).

Since there is such a wide variety of routing-related Combinatorial Optimization problems ([6], for example), there is much interest in finding models that can solve not just one specific type of routing problem, but can be applied to a wider set of problems. The challenge here lies defining a model that can take as input a generic problem structure and produce a generic schedule, which then can be adapted to different problem types. 
The projects goal is to investigate the application of MARL techniques to routing problems. Initially, the problem to tackle will be the TSP. If results are promising, the scope can be expanded to larger and/or more complex problems. Some decisions that have to be made are

 * How each agent is defined within the context of the problem (is each agent a vehicle, or perhaps a point?)
 * Which neural computational model to use for the agents
 * How (or if at all) the agents communicate with each other
 * Which actions the agents can take and how they should be penalized/rewarded (should agents be able to backtrack, for example?)

References:

[1] Macgregor et al., Human performance on the traveling salesman problem

[2] Alipour et al., A new multiagent reinforcement learning algorithm to sovle the symmetric traveling salesman problem

[3] Kool et al., Attention, Learn to Solve Routing Problems!

[4] Nazari et al., Reinforcement Learning for Solving the Vehicle Routing Problem

[5] Bello et al., Neural Combinatorial Optimization with Reinforcement Learning

[6] Peer et al., Shunting trains with deep reinforcement learning

